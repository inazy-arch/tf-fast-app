import streamlit as st
import json
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import uuid
import utils 

SPREADSHEET_KEY = "156ClxCEF8kOhLIOOqTw_qX1g58sLq9Q5qBYfpF9B5Wg"

# --- æ¥ç¶š ---
def get_gspread_client():
    try:
        key_dict = json.loads(st.secrets["gcp_service_account"]["json_content"])
        scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
        creds = Credentials.from_service_account_info(key_dict, scopes=scopes)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"GCP Error: {e}")
        return None

def get_sheet():
    client = get_gspread_client()
    if not client: return None
    try:
        return client.open_by_key(SPREADSHEET_KEY)
    except Exception as e:
        st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- Users ---
@st.cache_data(ttl=5)
def load_users():
    wb = get_sheet()
    if not wb: return {}
    try:
        try: sheet = wb.worksheet("members")
        except: return {}
        records = sheet.get_all_records()
        users = {}
        for r in records:
            uid = str(r.get("user_id"))
            if not uid: continue
            
            # JSONåˆ—ã®å¾©å…ƒ
            try: events = json.loads(str(r.get("events","")).replace("'", '"'))
            except: events = []
            if isinstance(events, str): events = [e.strip() for e in events.split(",") if e.strip()]
            
            try: pbs = json.loads(str(r.get("pbs","")).replace("'", '"'))
            except: pbs = {}
            
            # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸åŒ–
            u_data = r.copy()
            u_data["events"] = events
            u_data["pbs"] = pbs
            u_data["id"] = uid # idã‚­ãƒ¼ã‚‚ç¢ºä¿
            users[uid] = u_data
        return users
    except: return {}

def save_user(uid, user_data):
    """
    åˆ—ã®å ´æ‰€ã‚’è‡ªå‹•ã§æ¢ã—ã¦ä¿å­˜ã™ã‚‹ã€Œçµ¶å¯¾ã‚ºãƒ¬ãªã„ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    """
    wb = get_sheet()
    if not wb: return False
    try:
        try: sheet = wb.worksheet("members")
        except: return False
        
        # 1. 1è¡Œç›®ã®ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆåˆ—åï¼‰ã‚’ã™ã¹ã¦èª­ã¿è¾¼ã‚€
        headers = sheet.row_values(1)
        
        # 2. å¿…è¦ãªåˆ—ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆãªã‘ã‚Œã°ä½œã‚‹ï¼‰
        required_cols = ["user_id", "image", "bio", "name", "role", "role_title", "status", "block", "affiliation", "univ_cat", "grad_year", "events", "pbs", "name_kana", "password"]
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã«è¶³ã‚Šãªã„åˆ—ãŒã‚ã‚Œã°è¿½åŠ ã™ã‚‹æ©Ÿèƒ½
        missing_cols = [c for c in required_cols if c not in headers]
        if missing_cols:
            # è¶³ã‚Šãªã„åˆ—ã‚’å³ç«¯ã«è¿½åŠ 
            sheet.add_cols(len(missing_cols))
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›´æ–°
            first_row_len = len(headers)
            for i, col_name in enumerate(missing_cols):
                sheet.update_cell(1, first_row_len + i + 1, col_name)
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å†å–å¾—
            headers = sheet.row_values(1)

        # 3. ã©ã®ãƒ‡ãƒ¼ã‚¿ãŒä½•åˆ—ç›®ã‹ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼‰ã‚’ç‰¹å®š
        # ä¾‹: {"user_id": 0, "name": 1, "image": 13 ...}
        col_map = {name: i for i, name in enumerate(headers)}
        
        # 4. ä¿å­˜ã™ã‚‹è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œã‚‹
        # ã¾ãšã¯ç©ºæ–‡å­—ã§åŸ‹ã‚ãŸãƒªã‚¹ãƒˆã‚’ä½œã‚‹
        row_values = [""] * len(headers)
        
        # user_dataã®ä¸­èº«ã‚’ã€æ­£ã—ã„å ´æ‰€ã«é…ç½®ã™ã‚‹
        for key, val in user_data.items():
            if key in col_map:
                idx = col_map[key]
                # ãƒªã‚¹ãƒˆã‚„è¾æ›¸ã¯JSONæ–‡å­—åˆ—ã«
                if isinstance(val, (list, dict)):
                    val = json.dumps(val, ensure_ascii=False)
                row_values[idx] = val
        
        # 5. æ›´æ–°å¯¾è±¡ã®è¡Œã‚’æ¢ã™ (user_id ãŒä¸€è‡´ã™ã‚‹è¡Œ)
        cell = None
        try:
            # user_idåˆ—(Aåˆ—ã¨ã¯é™ã‚‰ãªã„ã®ã§æ¢ã™)
            uid_col_idx = col_map.get("user_id") + 1
            cell = sheet.find(str(uid), in_column=uid_col_idx)
        except:
            pass

        if cell:
            # æ›´æ–°: ãã®è¡Œã‚’ã¾ã‚‹ã”ã¨æ›¸ãæ›ãˆ
            # gspreadã® update ãƒ¡ã‚½ãƒƒãƒ‰ã§è¡Œæ›´æ–°
            # A1è¨˜æ³•ã‚’ä½œã‚‹ã®ãŒé¢å€’ãªã®ã§ã€è¡Œç•ªå·ã‚’æŒ‡å®šã—ã¦æ›´æ–°
            row_num = cell.row
            
            # å®‰å…¨ã®ãŸã‚ã€ã‚»ãƒ«ç¯„å›²ã‚’è¨ˆç®—ã—ã¦æ›´æ–°
            # 1è¡Œåˆ†ã®ç¯„å›² (ä¾‹: A2:Z2)
            end_col_char = chr(ord('A') + len(row_values) - 1)
            # åˆ—æ•°ãŒ26ã‚’è¶…ãˆã‚‹ã¨ 'AA' ã¨ã‹ã«ãªã‚‹ã®ã§ã€å³å¯†ã«ã¯ã“ã†æ›¸ãâ†“
            sheet.update(f"A{row_num}", [row_values])
        else:
            # æ–°è¦: æœ«å°¾ã«è¿½åŠ 
            sheet.append_row(row_values)
            
        load_users.clear()
        return True

    except Exception as e:
        print(f"Save User Error: {e}")
        return False

def save_users_batch(user_list):
    wb = get_sheet()
    if not wb: return False, "Connection Failed"
    try:
        sheet = wb.get_worksheet(0)
        records = sheet.get_all_records()
        existing_ids = {str(r["user_id"]): i for i, r in enumerate(records)}
        new_rows = []
        for u in user_list:
            uid = str(u["user_id"])
            if uid in existing_ids: continue 
            row_data = [
                uid, u.get("name", ""), u.get("name_kana", ""), "", "",
                str(u.get("password", "1234")), "player", "ãªã—", "", "å­¦éƒ¨",
                "ç¾å½¹", u.get("block", ""), u.get("affiliation", ""), "", "", "{}"
            ]
            new_rows.append(row_data)
        if new_rows:
            sheet.append_rows(new_rows)
            load_users.clear()
            return True, f"{len(new_rows)} users added."
        else: return True, "No new users."
    except Exception as e: return False, str(e)

def save_all_users_overwrite(users_list):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¹ãƒˆ(è¾æ›¸ã®ãƒªã‚¹ãƒˆ)ã‚’å—ã‘å–ã‚Šã€ã‚·ãƒ¼ãƒˆå…¨ä½“ã‚’ä¸Šæ›¸ãä¿å­˜ã™ã‚‹
    """
    wb = get_sheet()
    if not wb: return False
    try:
        sheet = wb.worksheet("members")
        
        # â˜…ä¿®æ­£: image ã¨ bio ã‚’è¿½åŠ ã—ã¦ã€å…¨15åˆ—ã«åˆã‚ã›ã¾ã—ãŸ
        header = [
            "user_id", "name", "password", "role", "role_title", "status", 
            "block", "affiliation", "univ_cat", "grad_year", 
            "events", "pbs", "name_kana", "image", "bio"
        ]
        
        # 2. ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆå½¢å¼(è¡Œ)ã«å¤‰æ›
        rows = [header] # 1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼
        
        for u in users_list:
            row = []
            for col in header:
                val = u.get(col, "")
                # ãƒªã‚¹ãƒˆã‚„è¾æ›¸ã¯æ–‡å­—åˆ—(JSON)ã«å¤‰æ›ã—ã¦ä¿å­˜
                if isinstance(val, (list, dict)):
                    val = json.dumps(val, ensure_ascii=False)
                row.append(val)
            rows.append(row)
            
        # 3. ã‚·ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦æ›¸ãè¾¼ã¿
        sheet.clear()
        sheet.update(rows) 
        
        load_users.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        return True
    except Exception as e:
        st.error(f"Save All Users Error: {e}")
        return False
    
# --- Competitions ---
@st.cache_data(ttl=5)
def load_competitions():
    wb = get_sheet()
    if not wb: return []
    try:
        try: sheet = wb.worksheet("competitions")
        except: return []
        
        records = sheet.get_all_records()
        
        # â˜…äº’æ›æ€§å¯¾å¿œ:
        # ã‚·ãƒ¼ãƒˆä¸Šã¯ "comp_id", "comp_name" ã§ã™ãŒã€
        # ã‚¢ãƒ—ãƒªå´ã®ã‚³ãƒ¼ãƒ‰(views)ãŒ "id", "name" ã‚’ä½¿ã£ã¦ã„ã‚‹ãŸã‚ã€
        # ä¸¡æ–¹ã®ã‚­ãƒ¼ã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«èª¿æ•´ã—ã¦è¿”ã—ã¾ã™ã€‚
        for r in records:
            # comp_id ãŒã‚ã‚Œã° id ã«ã‚‚å…¥ã‚Œã‚‹
            if "comp_id" in r:
                r["id"] = r["comp_id"]
            # comp_name ãŒã‚ã‚Œã° name ã«ã‚‚å…¥ã‚Œã‚‹
            if "comp_name" in r:
                r["name"] = r["comp_name"]
                
        return records
    except: return []

def save_competition(d):
    """
    å¤§ä¼šã‚’ä¿å­˜ã™ã‚‹
    åˆ—å®šç¾©: comp_id, comp_name, date, location, deadline, status, events, valid_start, valid_end
    """
    wb = get_sheet()
    if not wb: return False
    try:
        try: s = wb.worksheet("competitions")
        except: 
            s = wb.add_worksheet("competitions", 100, 10)
            # â˜…ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›´æ–°
            s.append_row(["comp_id", "comp_name", "date", "location", "deadline", "status", "events", "valid_start", "valid_end"])
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª (ã‚‚ã—å¤ã„ "id", "name" ã®ã¾ã¾ãªã‚‰ã€åˆ—åã ã‘ä¿®æ­£ã™ã‚‹ã‹ã€ä½œã‚Šç›´ã™ã®ãŒç„¡é›£ã§ã™ãŒã€ã“ã“ã§ã¯è¿½åŠ ã®ã¿è¡Œã„ã¾ã™)
        
        # æ–°è¦ä½œæˆ
        # d["name"] ã§æ¸¡ã£ã¦ãã‚‹ã“ã¨ãŒå¤šã„ã®ã§ã€ãã‚Œã‚’ comp_name ã¨ã—ã¦ä¿å­˜
        c_name = d.get("name") or d.get("comp_name")
        
        new_row = [
            str(uuid.uuid4())[:8],  # comp_id
            c_name,                 # comp_name
            str(d["date"]), 
            d["location"], 
            str(d["deadline"]),
            d.get("status", "å‹Ÿé›†ä¸­"), 
            json.dumps(d["events"], ensure_ascii=False),
            str(d.get("valid_start") or ""), 
            str(d.get("valid_end") or "")
        ]
        s.append_row(new_row)
        load_competitions.clear()
        return True
    except Exception as e: 
        st.error(f"Save Error: {e}")
        return False

def update_competition_status(comp_id, new_status):
    wb = get_sheet()
    if not wb: return False
    try:
        sheet = wb.worksheet("competitions")
        cell = sheet.find(str(comp_id))
        if cell:
            # statusã¯Fåˆ—(6)ã¨ä»®å®šã™ã‚‹ãŒã€æ¤œç´¢ã—ã¦ç‰¹å®šæ¨å¥¨
            header = sheet.row_values(1)
            col_idx = header.index("status") + 1
            sheet.update_cell(cell.row, col_idx, new_status)
            load_competitions.clear()
            return True
    except: pass
    return False

# --- Entries ---
@st.cache_data(ttl=5)
def load_entries(cid=None):
    wb = get_sheet()
    if not wb: return []
    try:
        sheet = wb.worksheet("entries")
        recs = sheet.get_all_records()
        if cid: return [r for r in recs if str(r.get("comp_id")) == str(cid)]
        return recs
    except: return []

def save_entry(d):
    wb = get_sheet()
    if not wb: return False
    try:
        try: s = wb.worksheet("entries")
        except: s = wb.add_worksheet("entries", 1000, 10)
        
        # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
        records = s.get_all_records()
        target_row = None
        for i, r in enumerate(records):
            if str(r.get("comp_id")) == str(d["comp_id"]) and str(r.get("user_id")) == str(d["user_id"]):
                target_row = i + 2
                break
        
        row_data = [
            d.get("entry_id", str(uuid.uuid4())[:8]),
            str(d["comp_id"]), str(d["user_id"]), d["user_name"],
            json.dumps(d["events"], ensure_ascii=False),
            json.dumps(d["times"], ensure_ascii=False),
            d.get("comment", ""), str(datetime.now())
        ]
        
        if target_row:
            # åˆ—æ•°ã«åˆã‚ã›ã¦æ›´æ–°ï¼ˆA:Hï¼‰
            s.update(f"A{target_row}:H{target_row}", [row_data])
        else:
            if not records: s.append_row(["entry_id","comp_id","user_id","user_name","events","times","comment","timestamp"])
            s.append_row(row_data)
            
        load_entries.clear()
        return True
    except: return False

# --- Results (Normalized) ---
# ã“ã“ãŒé‡è¦ï¼šä¿å­˜ã¯IDã®ã¿ã€èª­ã¿è¾¼ã¿æ™‚ã«JOIN

@st.cache_data(ttl=3)
def load_results(comp_id=None):
    wb = get_sheet()
    if not wb: return []
    try:
        try: sheet = wb.worksheet("results")
        except: return []
        
        raw_results = sheet.get_all_records()
        if not raw_results: return []

        # 1. å¤§ä¼šãƒã‚¹ã‚¿ã¨éƒ¨å“¡ãƒã‚¹ã‚¿ã‚’å–å¾—
        comps = load_competitions()
        comp_map = {str(c["id"]): c for c in comps}
        
        users = load_users() # ID -> UserData
        
        cleaned_results = []
        
        target_cid = str(comp_id) if comp_id else None
        
        for r in raw_results:
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            row_cid = str(r.get("comp_id", ""))
            if target_cid and row_cid != target_cid: continue
            
            row_uid = str(r.get("user_id", ""))
            
            # --- JOINå‡¦ç† ---
            # å¤§ä¼šæƒ…å ±
            c_info = comp_map.get(row_cid, {})
            comp_name = c_info.get("name", "æœªç™»éŒ²å¤§ä¼š")
            comp_date = str(c_info.get("date", "2000-01-01"))
            
            # éƒ¨å“¡æƒ…å ±
            u_info = users.get(row_uid, {})
            user_name = u_info.get("name", "æœªç™»éŒ²é¸æ‰‹")
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ (UIè¡¨ç¤ºç”¨ã«åç§°ã‚’å«ã‚ã‚‹)
            cleaned_results.append({
                "result_id": str(r.get("result_id", "")),
                "comp_id": row_cid,
                "comp_name": comp_name, # è¡¨ç¤ºç”¨
                "date": comp_date,      # è¡¨ç¤ºç”¨
                
                "user_id": row_uid,
                "user_name": user_name, # è¡¨ç¤ºç”¨
                
                "event": str(r.get("event", "")),
                "division": str(r.get("division", "")),
                "round": str(r.get("round", "")),
                "heat": str(r.get("heat", "")),
                "lane": str(r.get("lane", "")),
                "result": str(r.get("result", "")),
                "wind": str(r.get("wind", "")),
                "rank": str(r.get("rank", "")),
                "comment": str(r.get("comment", ""))
            })
            
        return cleaned_results
    except Exception as e:
        print(e)
        return []

def save_results_batch(results_list):
    """
    çµæœãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„å ´åˆã¯å¼·åˆ¶çš„ã«æŒ¿å…¥ã™ã‚‹ã€‚
    """
    wb = get_sheet()
    if not wb: return False
    try:
        # ã‚·ãƒ¼ãƒˆå–å¾—ï¼ˆãªã‘ã‚Œã°ä½œæˆï¼‰
        try: sheet = wb.worksheet("results")
        except: sheet = wb.add_worksheet("results", 5000, 15)
        
        # â˜…æ±ºå®šç‰ˆã®ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
        header = [
            "result_id", "comp_id", "user_id", "event", 
            "division", "round", "heat", "lane", 
            "result", "wind", "rank", "comment"
        ]
        
        # â˜…ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: get_all_values() ã§ã¯ãªãã€å…·ä½“çš„ã«1è¡Œç›®ã‚’ç¢ºèªã™ã‚‹
        # 1è¡Œç›®ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        first_row = sheet.row_values(1)
        
        # ã€Œ1è¡Œç›®ãŒç©ºã£ã½ã€ã¾ãŸã¯ã€Œ1è¡Œç›®ã®å…ˆé ­ãŒ result_id ã§ã¯ãªã„ã€å ´åˆ
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã€æŒ¿å…¥ã€‘ã—ã¾ã™ï¼ˆappendã§ã¯ãªãinsertã‚’ä½¿ã†ã“ã¨ã§æœ€ä¸Šæ®µã‚’ç¢ºä¿ï¼‰
        if not first_row or first_row[0] != "result_id":
            sheet.insert_row(header, index=1)
            
        # ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        rows_to_add = []
        for r in results_list:
            if not r.get("comp_id") or not r.get("result"):
                continue
                
            row = [
                str(r.get("result_id", uuid.uuid4())), 
                str(r.get("comp_id")),
                str(r.get("user_id", "")),
                str(r.get("event", "")),
                str(r.get("division", "")),
                str(r.get("round", "")),
                str(r.get("heat", "")),
                str(r.get("lane", "")),
                str(r.get("result", "")),
                str(r.get("wind", "")),
                str(r.get("rank", "")),
                str(r.get("comment", ""))
            ]
            rows_to_add.append(row)
            
        if rows_to_add:
            sheet.append_rows(rows_to_add)
            load_results.clear()
            return True
        
        return True
        
    except Exception as e:
        st.error(f"Save Error: {e}")
        return False

# --- Start List (Start List ã‚‚æ­£è¦åŒ–æ€æƒ³ã§æ‰±ã†ãŒã€ä¾¿å®œä¸Šåå‰ã‚‚ä¿æŒã™ã‚‹å ´åˆãŒã‚ã‚‹ã€‚ä»Šå›ã¯IDãƒ™ãƒ¼ã‚¹ã§æ¤œç´¢) ---
@st.cache_data(ttl=10)
def load_start_list(comp_id):
    """ æŒ‡å®šã•ã‚ŒãŸå¤§ä¼šã®ã‚¹ã‚¿ãƒ¼ãƒˆãƒªã‚¹ãƒˆï¼ˆç•ªçµ„ç·¨æˆï¼‰ã‚’èª­ã¿è¾¼ã‚€ """
    wb = get_sheet()
    if not wb: return []
    try:
        try: sheet = wb.worksheet("start_list")
        except: return []
        
        records = sheet.get_all_records()
        # comp_id ãŒä¸€è‡´ã™ã‚‹ã‚‚ã®ã ã‘æŠ½å‡º (æ–‡å­—åˆ—ã«ã—ã¦æ¯”è¼ƒ)
        target_str = str(comp_id)
        return [r for r in records if str(r.get("comp_id")) == target_str]
    except:
        return []

def save_start_list_overwrite(comp_id, data_list):
    """ æŒ‡å®šã•ã‚ŒãŸå¤§ä¼šã®ã‚¹ã‚¿ãƒ¼ãƒˆãƒªã‚¹ãƒˆã‚’ä¸Šæ›¸ãä¿å­˜ã™ã‚‹ """
    wb = get_sheet()
    if not wb: return False
    try:
        try: sheet = wb.worksheet("start_list")
        except: sheet = wb.add_worksheet("start_list", 1000, 20)
        
        # 1. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å…¨å–å¾—
        all_records = sheet.get_all_records()
        
        # 2. ä»Šå›ä¿å­˜ã™ã‚‹å¤§ä¼šä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ã¯æ®‹ã™
        target_str = str(comp_id)
        kept_records = [r for r in all_records if str(r.get("comp_id")) != target_str]
        
        # 3. æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ï¼ˆcomp_idã‚’ä»˜ä¸ï¼‰
        for row in data_list:
            row["comp_id"] = target_str
            kept_records.append(row)
        
        # 4. ã‚·ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦å…¨æ›¸ãè¾¼ã¿
        if kept_records:
            header = list(kept_records[0].keys())
            # é †ç•ªã‚’æ•´ãˆã‚‹ãŸã‚ã®å›ºå®šãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
            preferred_order = ["comp_id", "ç«¶æŠ€å§‹", "ç¨®ç›®", "çµ„", "ãƒ¬ãƒ¼ãƒ³", "ãƒŠãƒ³ãƒãƒ¼", "æ°å", "ç¾PB", "ç›®æ¨™è¨˜éŒ²", "æ‰€å±", "æ‹›é›†å§‹", "æ‹›é›†çµ‚", "å‚™è€ƒ"]
            # ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ã‚­ãƒ¼ã ã‘ã§ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œã‚‹
            final_header = [h for h in preferred_order if h in header] + [h for h in header if h not in preferred_order]
            
            rows = [final_header]
            for r in kept_records:
                rows.append([r.get(col, "") for col in final_header])
            
            sheet.clear()
            sheet.update(rows)
        else:
            sheet.clear() # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã«ãªã£ãŸå ´åˆ
            
        load_start_list.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        return True
    except Exception as e:
        st.error(f"Save Start List Error: {e}")
        return False

###########################################################################
###########################################################################
# get_user_best_in_period, News, Blog, Accountingãªã©ã¯æ—¢å­˜ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
@st.cache_data(ttl=5)
def load_fees():
    """ é›†é‡‘ã‚¤ãƒ™ãƒ³ãƒˆä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ """
    wb = get_sheet()
    if not wb: return []
    try:
        try: sheet = wb.worksheet("accounting")
        except: return []
        
        records = sheet.get_all_records()
        # status_map (èª°ãŒæ‰•ã£ãŸã‹) ã¯JSONãªã®ã§å¾©å…ƒ
        for r in records:
            if isinstance(r.get("status_map"), str):
                try: r["status_map"] = json.loads(r["status_map"].replace("'", '"'))
                except: r["status_map"] = {}
        return records
    except:
        return []

def save_fee_event(fee_data):
    """ æ–°ã—ã„é›†é‡‘ã‚¤ãƒ™ãƒ³ãƒˆã‚’ä½œæˆãƒ»æ›´æ–° """
    wb = get_sheet()
    if not wb: return False
    try:
        try: sheet = wb.worksheet("accounting")
        except: sheet = wb.add_worksheet("accounting", 1000, 10)
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å…¨å–å¾—
        all_records = sheet.get_all_records()
        
        # IDãŒä¸€è‡´ã™ã‚‹ã‚‚ã®ãŒã‚ã‚Œã°æ›´æ–°ã€ãªã‘ã‚Œã°è¿½åŠ 
        target_id = str(fee_data["id"])
        updated = False
        
        # ä¿å­˜ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
        save_row = {
            "id": target_id,
            "title": fee_data["title"],
            "amount": fee_data["amount"],
            "deadline": fee_data["deadline"],
            # è¾æ›¸ã¯JSONæ–‡å­—åˆ—åŒ–
            "status_map": json.dumps(fee_data["status_map"], ensure_ascii=False)
        }
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª & è¡Œæ§‹ç¯‰
        header = ["id", "title", "amount", "deadline", "status_map"]
        
        # ã‚·ãƒ¼ãƒˆãŒç©ºãªã‚‰ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ 
        if not all_records and sheet.row_values(1) == []:
            sheet.append_row(header)
            all_records = []

        # æ›´æ–°å¯¾è±¡ã‚’æ¢ã™
        target_row_idx = -1
        for i, r in enumerate(all_records):
            if str(r.get("id")) == target_id:
                target_row_idx = i + 2 # 1è¡Œç›®ãƒ˜ãƒƒãƒ€ãƒ¼ + 0å§‹ã¾ã‚Šè£œæ­£
                break
        
        row_vals = [save_row[h] for h in header]
        
        if target_row_idx > 0:
            # æ›´æ–° (Aåˆ—ï½Eåˆ—)
            sheet.update(f"A{target_row_idx}:E{target_row_idx}", [row_vals])
        else:
            # æ–°è¦è¿½åŠ 
            sheet.append_row(row_vals)
            
        load_fees.clear()
        return True
    except Exception as e:
        print(f"Fee Save Error: {e}")
        return False
    
# db.py ã«è¿½åŠ ãƒ»ä¿®æ­£

# === ğŸ“¢ å…¬å¼News (è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹çµæœå ±å‘Š) ===
@st.cache_data(ttl=10)
def load_news():
    wb = get_sheet()
    if not wb: return []
    try:
        # ã‚·ãƒ¼ãƒˆåã‚’ 'news' ã«å¤‰æ›´
        try: sheet = wb.worksheet("news")
        except: return []
        records = sheet.get_all_records()
        records.sort(key=lambda x: x.get("date", ""), reverse=True)
        return records
    except: return []

def save_news(news_data):
    """ Newsã‚’ä¿å­˜ (ID, date, title, content) """
    wb = get_sheet()
    if not wb: return False
    try:
        try: sheet = wb.worksheet("news")
        except: sheet = wb.add_worksheet("news", 1000, 10)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèª
        if not sheet.get_all_values():
            sheet.append_row(["id", "date", "title", "content"]) # ç”»åƒã‚„è‘—è€…ã¯ä¸è¦
            
        sheet.append_row([
            news_data["id"], 
            news_data["date"], 
            news_data["title"], 
            news_data["content"]
        ])
        load_news.clear()
        return True
    except: return False

# === ğŸ“ é¸æ‰‹ãƒ–ãƒ­ã‚° ===
@st.cache_data(ttl=10)
def load_blogs():
    wb = get_sheet()
    if not wb: return []
    try:
        try: sheet = wb.worksheet("blogs")
        except: return []
        records = sheet.get_all_records()
        records.sort(key=lambda x: str(x.get("created_at", "")), reverse=True)
        return records
    except: return []

def save_blog(blog_data):
    """ ãƒ–ãƒ­ã‚°ã‚’ä¿å­˜ """
    wb = get_sheet()
    if not wb: return False
    try:
        try: sheet = wb.worksheet("blogs")
        except: sheet = wb.add_worksheet("blogs", 1000, 10)
        
        header = ["id", "created_at", "title", "content", "author_name", "author_id", "image"]
        if not sheet.get_all_values(): sheet.append_row(header)
        
        # æ–°è¦è¿½åŠ ã®ã¿å®Ÿè£…ï¼ˆç·¨é›†ã¯çœç•¥ï¼‰
        sheet.append_row([
            blog_data["id"],
            blog_data["created_at"],
            blog_data["title"],
            blog_data["content"],
            blog_data["author_name"],
            blog_data["author_id"],
            blog_data.get("image", "")
        ])
        load_blogs.clear()
        return True
    except: return False

# --- db.py ã®æœ«å°¾ã«è¿½åŠ  ---

def get_user_best_in_period(user_id, event, start_date=None, end_date=None):
    """
    æŒ‡å®šã•ã‚ŒãŸæœŸé–“å†…ã§ã®ã€ç‰¹å®šã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ç¨®ç›®ã®ãƒ™ã‚¹ãƒˆè¨˜éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚
    ï¼ˆãƒˆãƒ©ãƒƒã‚¯ç¨®ç›®ã¯ã‚¿ã‚¤ãƒ ã®æœ€å°å€¤ã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¨®ç›®ã¯è·é›¢ã®æœ€å¤§å€¤ã‚’ãƒ™ã‚¹ãƒˆã¨ã¿ãªã—ã¾ã™ï¼‰
    """
    # 1. å…¨ãƒªã‚¶ãƒ«ãƒˆã‚’èª­ã¿è¾¼ã‚€
    results = load_results(None)
    
    # 2. å¯¾è±¡ã®è¨˜éŒ²ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæŠ½å‡ºï¼‰
    targets = []
    for r in results:
        # IDãƒã‚§ãƒƒã‚¯
        if str(r.get("user_id")) != str(user_id): continue
        # ç¨®ç›®ãƒã‚§ãƒƒã‚¯
        if r.get("event") != event: continue
        
        # æ—¥ä»˜ãƒã‚§ãƒƒã‚¯ï¼ˆæœŸé–“æŒ‡å®šãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        r_date = r.get("date") # "YYYY-MM-DD"å½¢å¼
        if not r_date: continue
        
        if start_date and r_date < start_date: continue
        if end_date and r_date > end_date: continue
        
        targets.append(r)

    if not targets:
        return None

    # 3. ãƒ™ã‚¹ãƒˆè¨˜éŒ²ã‚’é¸å®šã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
    best_record = None
    best_val = None
    
    # ç°¡æ˜“åˆ¤å®š: ç¨®ç›®åã«ç‰¹å®šã®æ–‡å­—ãŒå«ã¾ã‚Œã‚‹å ´åˆã¯ã€Œãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¨®ç›®ï¼ˆå¤§ãã„æ–¹ãŒè‰¯ã„ï¼‰ã€ã¨ã™ã‚‹
    # ãã‚Œä»¥å¤–ã¯ã€Œãƒˆãƒ©ãƒƒã‚¯ç¨®ç›®ï¼ˆå°ã•ã„æ–¹ãŒè‰¯ã„ï¼‰ã€ã¨ã™ã‚‹
    is_field = False
    field_keywords = ["è·³", "æŠ•", "ç ²ä¸¸", "å††ç›¤", "ã‚„ã‚Š", "ãƒãƒ³ãƒãƒ¼", "ã‚¸ãƒ£ãƒ™ãƒªãƒƒã‚¯ã‚¹"]
    for k in field_keywords:
        if k in event:
            is_field = True
            break

    for r in targets:
        try:
            # è¨˜éŒ²ã‚’æ•°å€¤ã«å¤‰æ›ã—ã¦ã¿ã‚‹
            val = float(str(r["result"]).strip())
        except:
            # æ•°å€¤ã«ã§ããªã„ã‚‚ã®ï¼ˆDNS, NM, æ¬ å ´ãªã©ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue

        if best_val is None:
            best_val = val
            best_record = r
        else:
            if is_field:
                # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: æ•°å€¤ãŒå¤§ãã„æ–¹ãŒè‰¯ã„
                if val > best_val:
                    best_val = val
                    best_record = r
            else:
                # ãƒˆãƒ©ãƒƒã‚¯: æ•°å€¤ï¼ˆã‚¿ã‚¤ãƒ ï¼‰ãŒå°ã•ã„æ–¹ãŒè‰¯ã„
                if val < best_val:
                    best_val = val
                    best_record = r
                    
    return best_record